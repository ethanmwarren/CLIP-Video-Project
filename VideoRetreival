{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ced9d31-ec9b-4636-ac0c-487291f93b10",
   "metadata": {},
   "source": [
    "### Video Retrieval\n",
    "\n",
    "We now should in theory have everything implemented that we need to be able to retrieve video from a text prompt. In this notebook I want to try out video retrieval with a few short videos I downloaded off of youtube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb19ee73-88b1-4784-8f0f-a817ea129607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import clip\n",
    "import torch\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46d455e-cb6b-418b-b62c-4fd0c6dda071",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Function Defintions\n",
    "These are the function definitions we have from previous scripts to process the videos into encoded vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56398bb4-fd85-4bff-8b15-6c2711a31e83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_saving_frames_durations(cap, saving_fps):\n",
    "    '''A function that returns the list of durations where to save the frames'''\n",
    "    s = []\n",
    "    # get the clip duration by dividing number of frames by the number of frames per second\n",
    "    clip_duration = cap.get(cv2.CAP_PROP_FRAME_COUNT) / cap.get(cv2.CAP_PROP_FPS)\n",
    "    # use np.arange() to make floating-point steps\n",
    "    for i in np.arange(0, clip_duration, 1 / saving_fps):\n",
    "        s.append(i)\n",
    "    return s\n",
    "\n",
    "def save_video_frames(video_file, SAVING_FRAMES_PER_SECOND):\n",
    "    '''A function that saves the individual frames of a video, returning a list containing\n",
    "    each frame, saved as an image saved in a numpy array.\n",
    "    \n",
    "    Saving frames per second is the desired number of frames to be saved from each second\n",
    "    of the video.\n",
    "    '''\n",
    "    \n",
    "    # read the video file\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    \n",
    "    # get the fps of the video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # if the SAVIGN_FRAMES_PER_SECOND is above video fps, then set it to fps (as maximum)\n",
    "    saving_frames_per_second = min(fps, SAVING_FRAMES_PER_SECOND)\n",
    "    \n",
    "    # get the list and duration spots to save\n",
    "    saving_frames_durations = get_saving_frames_durations(cap, saving_frames_per_second)\n",
    "    \n",
    "    # start the loop\n",
    "    count = 0\n",
    "    all_frames = []\n",
    "    while True:\n",
    "        is_read, frame = cap.read()\n",
    "        if not is_read:\n",
    "            # break out of the loop if there are no frames to read\n",
    "            break\n",
    "        # Reverse colors to be in RGB format\n",
    "        frame = frame[...,::-1]\n",
    "        # get the duration by dividing the frame count by the FPS\n",
    "        frame_duration = count / fps\n",
    "        try:\n",
    "            # get the earliest duration to save\n",
    "            closest_duration = saving_frames_durations[0]\n",
    "        except IndexError:\n",
    "            # the list is empty, all duration frames were saved\n",
    "            break\n",
    "        if frame_duration >= closest_duration:\n",
    "            # if closest duration is less than or equals the frame duration, \n",
    "            # then save the frame\n",
    "            all_frames.append(frame) \n",
    "            # drop the duration spot from the list, since this duration spot is already saved\n",
    "            try:\n",
    "                saving_frames_durations.pop(0)\n",
    "            except IndexError:\n",
    "                pass\n",
    "        # increment the frame count\n",
    "        count += 1\n",
    "    \n",
    "    # video = np.stack(all_frames, axis=0)\n",
    "    return all_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff830f74-d8e1-4c3c-bb68-13b95e174887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_clip(frames, model, preprocess, device = \"cpu\"):\n",
    "    image_inputs = [preprocess(Image.fromarray(image)).unsqueeze(0).to(device) for image in frames]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_features = [model.encode_image(image_input) for image_input in image_inputs]\n",
    "        \n",
    "    return image_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2f8767b-ce6b-4be9-8bac-26f557d8fb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_vectors(encoded_frames):\n",
    "    '''A function that returns the average image from all frames in a list.'''\n",
    "    \n",
    "    number_of_frames = len(encoded_frames)\n",
    "    \n",
    "    # Initialize average_frame. We will be adding the rest of the frames in the for loop\n",
    "    average_vector = encoded_frames[0] / number_of_frames\n",
    "    for i in range(1, len(encoded_frames)):\n",
    "        average_vector += encoded_frames[i] / number_of_frames\n",
    "    \n",
    "    return average_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f47b41b-e28e-426d-aa0f-a3c5e4d1d2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_file, model, preprocess, saving_frames_per_second = 10, device = \"cpu\"):\n",
    "    frames = save_video_frames(video_file, saving_frames_per_second)\n",
    "    encoded_frames = apply_clip(frames, model, preprocess, device)\n",
    "    average_vector = average_vectors(encoded_frames)\n",
    "    return average_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff33b422-b143-4940-b9dd-56df57325548",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Process videos\n",
    "\n",
    "Define this function to process videos. It takes a list of file names as inputs and returns the average features of each video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "599306ea-a122-47ed-8f11-8c48464b342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_videos(video_names, model, preprocess, saving_frames_per_second = 10):\n",
    "    video_features = []\n",
    "    for file_name in video_names:\n",
    "        file_name += '.mp4'\n",
    "        video_features.append(process_video(file_name, model, preprocess, saving_frames_per_second))\n",
    "\n",
    "    video_features = torch.cat(video_features)\n",
    "    return video_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98a41d94-381b-47ce-9d8f-41588561c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = clip.load('ViT-B/32', device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43a0ccba-e730-4bb0-872d-56a2d9a2ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_names = ['football', 'lion', 'sky', 'chess', 'watermelon']\n",
    "video_features = encode_videos(video_names, model, preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d11484-8143-4e40-bd31-b6f7c7e160c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Text Input\n",
    "\n",
    "We have the videos processed, so now we can give a text input to clip and find the most similar video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80cbc552-4abd-47bb-80b5-66bb23b5d9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_video(search_input, video_features, video_names):\n",
    "    text_input = clip.tokenize(\"a photo of\" + search_input).to(\"cpu\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        text_features = model.encode_text(text_input)\n",
    "        \n",
    "    video_features /= video_features.norm(dim=-1, keepdim=True) \n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    similarity = (100 * text_features @ video_features.T).softmax(dim=-1)\n",
    "\n",
    "    value, index = similarity.topk(1)\n",
    "    \n",
    "    print(f\"With {100*value.item():.2f}%, the top video is: {video_names[index.item()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9772972-3be5-4937-bc3a-18028ec1d24c",
   "metadata": {},
   "source": [
    "## At last!\n",
    "To search for a video, just input text into the search input variable. The functions will do the rest behind the scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b6b2ad05-0381-4b75-b939-84b90636aeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 99.84%, the top video is: football\n"
     ]
    }
   ],
   "source": [
    "search_input = \"soccer\"\n",
    "\n",
    "retrieve_video(search_input, video_features, video_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f56600-9a34-4578-a0f4-6ea0286331a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### We can also define a function to play the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6fd1385-9376-4bab-aabb-4dfdcdd8f172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_video(file_name):\n",
    "    cap = cv2.VideoCapture(file_name + '.mp4')\n",
    "\n",
    "    # Check if camera opened successfully\n",
    "    if (cap.isOpened()== False):\n",
    "        print(\"Error opening video file\")\n",
    "\n",
    "    # Read until video is completed\n",
    "    while(cap.isOpened()):\n",
    "\n",
    "    # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "        # Display the resulting frame\n",
    "            cv2.imshow('Frame', frame)\n",
    "\n",
    "        # Press Q on keyboard to exit\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    # Break the loop\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # When everything done, release\n",
    "    # the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
